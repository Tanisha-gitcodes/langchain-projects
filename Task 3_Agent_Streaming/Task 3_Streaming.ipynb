{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6fe41db-fcae-43e3-b18a-b285b5d6b582",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:02:37.447165Z",
     "start_time": "2025-06-17T14:02:35.041619Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: --quiet--openai\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet--openai langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3e1e8b-1feb-4867-9b77-e2feebf234c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:02:49.192918Z",
     "start_time": "2025-06-17T14:02:37.476688Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a7061b-85c0-4952-94c8-71e509e1dc64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:02:49.415214Z",
     "start_time": "2025-06-17T14:02:49.401050Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Chain: Prompt - LLM - OutputParser\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56371a65-96e8-4b86-959a-13f574615a05",
   "metadata": {},
   "source": [
    "### Invoke Text Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab762a69-d8f5-403e-aa7b-46fbc86f30fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:02:49.474710Z",
     "start_time": "2025-06-17T14:02:49.468861Z"
    }
   },
   "outputs": [],
   "source": [
    "def invoke_joke(topic: str):\n",
    "    result = chain.invoke({\"topic\": topic})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2deab5-bf77-4c01-9a3c-5b202dbaa331",
   "metadata": {},
   "source": [
    "### Streaming Text Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd2ade19-92c4-46f2-8bfc-7b9adee23225",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:02:49.566680Z",
     "start_time": "2025-06-17T14:02:49.560846Z"
    }
   },
   "outputs": [],
   "source": [
    "async def stream_joke(topic: str):\n",
    "    async for chunk in chain.astream({\"topic\": topic}):\n",
    "        print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df059036-60dd-4b65-b31b-6722e5e7c1e4",
   "metadata": {},
   "source": [
    "### Raw Event Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94d6c431-bdf5-4e3d-8d9d-07e94855dfe2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:02:49.652321Z",
     "start_time": "2025-06-17T14:02:49.623538Z"
    }
   },
   "outputs": [],
   "source": [
    "async def stream_events_joke(topic: str):\n",
    "    async for event in chain.astream_events({\"topic\": topic}):\n",
    "        if event[\"event\"] == \"on_chat_model_stream\":\n",
    "            print(event[\"data\"][\"chunk\"].content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac49651d-0e16-4477-b9e2-4e0e5d41b001",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a836c703-0d12-402c-98a5-68a31f7a6bec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:02:49.702584Z",
     "start_time": "2025-06-17T14:02:49.689924Z"
    }
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "nest_asyncio.apply()  # Allows nested event loops\n",
    "\n",
    "async def main():\n",
    "    topic_entered = input(\"What topic would you like to hear a joke on? \")\n",
    "    stream_option = input(\"Do you want the output to be streamed? [Y/N] \").upper()\n",
    "\n",
    "    while stream_option not in [\"Y\", \"N\"]:\n",
    "        stream_option = input(\"Please enter 'Y' or 'N': \").upper()\n",
    "\n",
    "    if stream_option == \"Y\":\n",
    "        await stream_joke(topic_entered)\n",
    "    else:\n",
    "        invoke_joke(topic_entered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "225c3b66dee20c9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:04:02.718889Z",
     "start_time": "2025-06-17T14:02:49.741840Z"
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What topic would you like to hear a joke on?  tech\n",
      "Do you want the output to be streamed? [Y/N]  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the computer go to therapy?\n",
      "\n",
      "Because it had too many bytes from its past!\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7237dbf1-6178-4744-90cc-7ab1e02027f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T17:01:57.386184Z",
     "start_time": "2025-06-16T17:01:57.364903Z"
    }
   },
   "outputs": [],
   "source": [
    "# await stream_events_joke(topic_entered)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
